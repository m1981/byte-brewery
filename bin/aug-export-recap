#!/usr/bin/env python3
"""
A tool to generate a readable Markdown recap from an Agent AI state file.

This script parses a JSON state file, extracts conversation histories,
and generates a structured, navigable Markdown document. It filters out
agent file-edit code blocks for cleaner output.
"""
import sys
import re
import argparse
import json
from pathlib import Path
from datetime import datetime, timezone
from typing import Dict, Any, List, Optional, Tuple


# --- Text Processing Utilities ---

def filter_file_edits(text: str) -> str:
    """
    Finds agent-generated file edit blocks and replaces them with a summary message.
    """
    if not text:
        return ""

    # Regex to find code blocks with path and mode attributes.
    # It's non-greedy and handles multiline content.
    pattern = re.compile(
        r"`` `(\w*)\s*path=([^\s]+)\s+mode=\w+\n.*?\n`` `",
        re.DOTALL
    )

    def replacer(match: re.Match) -> str:
        """Replacement function to create a summary line."""
        path = match.group(2)
        return f"\n> *[File edit performed on `{path}`]*\n"

    return pattern.sub(replacer, text)


def clean_text_content(text: Optional[str]) -> str:
    """
    Non-destructively clean text content for Markdown display.
    Handles JSON escape sequences and filters file edits.
    """
    if not text:
        return ""

    text = str(text)

    # Decode unicode escapes like \u2705 first
    # This regex-based approach is safer than encode/decode for malformed strings
    def decode_unicode_escapes(match):
        try:
            return chr(int(match.group(1), 16))
        except (ValueError, TypeError):
            return match.group(0)  # Return original if conversion fails

    text = re.sub(r'\\u([0-9a-fA-F]{4})', decode_unicode_escapes, text)

    # Normalize escaped newlines to actual newlines
    text = text.replace('\\n', '\n')

    # Remove only ASCII control characters, preserving tabs and newlines
    text = re.sub(r'[\x00-\x08\x0b\x0c\x0e-\x1f\x7f]', '', text)

    return text


def smart_truncate(text: str, max_length: int) -> str:
    """
    Truncate text for a summary, prioritizing the first line and then
    falling back to sentence or word boundaries.
    """
    if not text:
        return ""

    first_line = next((line for line in text.splitlines() if line.strip()), "").strip()

    if len(first_line) > max_length:
        return first_line[:max_length].strip() + "..."
    if len(first_line) > 60:
        return first_line

    if len(text) <= max_length:
        return text.replace('\n', ' ')

    truncated = text[:max_length]

    sentence_ends = ['. ', '.\n', '? ', '?\n', '! ', '!\n', '```']
    best_cut = -1
    for ending in sentence_ends:
        pos = truncated.rfind(ending)
        if pos > max_length * 0.6:
            best_cut = max(best_cut, pos + len(ending))

    if best_cut > 0:
        return text[:best_cut].replace('\n', ' ') + "..."

    last_space = truncated.rfind(' ')
    if last_space > max_length * 0.7:
        return text[:last_space].replace('\n', ' ') + "..."

    return text[:max_length].replace('\n', ' ') + "..."


# --- Markdown Generation ---

def get_conversation_title(conv: Dict[str, Any]) -> str:
    """Extract a clean and concise title from a conversation object."""
    name = conv.get("name", "").strip()
    if name:
        return name

    chat_history = conv.get("chatHistory", [])
    if not chat_history:
        return "Empty Conversation"

    first_message_request = chat_history[0].get("request_message", "")
    if not first_message_request:
        return "Untitled Conversation"

    first_line = first_message_request.split('\n')[0].strip()
    title = re.sub(
        r'^(act as|please|can you|explain|help me with|i need)\s+',
        '', first_line, flags=re.IGNORECASE
    ).strip()

    return smart_truncate(title, 80) or "Untitled Conversation"


def create_markdown_anchor(text: str) -> str:
    """Create a GitHub-style markdown anchor from a title."""
    anchor = re.sub(r'[^\w\s-]', '', text.lower())
    anchor = re.sub(r'[-\s]+', '-', anchor).strip('-')
    return anchor


def _parse_iso_date(date_str: str) -> Optional[datetime]:
    """Parse an ISO date string, handling 'Z' timezone."""
    if not date_str:
        return None
    try:
        return datetime.fromisoformat(date_str.replace('Z', '+00:00'))
    except (ValueError, TypeError):
        return None


def extract_conversations_markdown(json_data: Dict[str, Any], since: Optional[str]) -> str:
    """Generate a full Markdown recap from the conversation data."""
    conversations = json_data.get("conversations", {})
    since_date = _parse_iso_date(f"{since}T00:00:00+00:00") if since else None

    sorted_convs: List[Tuple[str, Dict[str, Any]]] = sorted(
        conversations.items(),
        key=lambda item: item[1].get("createdAtIso", ""),
        reverse=True
    )

    filtered_convs = [
        (conv_id, conv) for conv_id, conv in sorted_convs
        if not since_date or (_parse_iso_date(conv.get("createdAtIso", "")) or datetime.min.replace(
            tzinfo=timezone.utc)) >= since_date
    ]

    md = ["# Project Recap"]

    md.append("\n## Table of Contents\n")
    if not filtered_convs:
        md.append("*No conversations found for the selected period.*")
    else:
        for _, conv in filtered_convs:
            title = get_conversation_title(conv)
            anchor = create_markdown_anchor(title)
            created_at = (conv.get("createdAtIso") or "Unknown")[:10]
            pin_icon = "üìå " if conv.get("isPinned") else ""
            md.append(f"- [{pin_icon}{title}](#{anchor}) *({created_at})*")

    for conv_id, conv in filtered_convs:
        md.append("\n---\n")
        title = get_conversation_title(conv)
        pin_icon = "üìå " if conv.get("isPinned") else ""
        md.append(f"## {pin_icon}{title}")

        created_at = conv.get("createdAtIso", "N/A")
        last_interaction = conv.get("lastInteractedAtIso", "N/A")

        md.append(f"| ID | Created | Last Interaction |")
        md.append(f"|:---|:---|:---|")
        md.append(f"| `{conv_id[:8]}` | {created_at} | {last_interaction} |")

        chat_history = conv.get("chatHistory", [])
        if not chat_history:
            md.append("\n*This conversation has no messages.*")
            continue

        mentioned_files = set()
        for msg in chat_history:
            for item in msg.get("mentioned_items", []):
                if name := item.get("name"):
                    mentioned_files.add(f"`{name}`")
        if mentioned_files:
            md.append(f"\n**Mentioned Files:** {', '.join(sorted(list(mentioned_files)))}")

        for i, msg in enumerate(chat_history, 1):
            request_clean = clean_text_content(msg.get("request_message"))

            # Clean and then filter the response
            response_clean = clean_text_content(msg.get("response_text"))
            response_filtered = filter_file_edits(response_clean)

            status = msg.get("status", "unknown")
            timestamp = msg.get("timestamp", "")

            status_icon = {
                "success": "‚úÖ", "error": "‚ùå", "pending": "‚è≥",
                "draft": "üìù", "cancelled": "üö´"
            }.get(status, "‚ùì")

            md.append(f"\n### Turn {i} ({status.capitalize()}) {status_icon}")
            if timestamp:
                md.append(f"*{timestamp}*\n")

            if request_clean:
                summary = smart_truncate(request_clean, 200)
                md.append(f'<details>')
                md.append(f'  <summary><strong>Request:</strong> {summary}</summary>')
                md.append(f'\n```\n{request_clean}\n```\n</details>\n')

            if response_filtered:
                summary = smart_truncate(response_filtered, 300)
                md.append(f'<details>')
                md.append(f'  <summary><strong>Response:</strong> {summary}</summary>')
                md.append(f'\n{response_filtered}\n</details>\n')

    return "\n".join(md)


# --- Main Execution ---

def main():
    """Main function to parse arguments and generate the recap."""
    parser = argparse.ArgumentParser(
        description="Generate a readable Markdown recap from an Agent AI state file.",
        formatter_class=argparse.RawTextHelpFormatter
    )
    parser.add_argument(
        "input_file", nargs='?', default='-',
        help="Input JSON file path. Reads from stdin if not provided."
    )
    parser.add_argument(
        "-o", "--output",
        help="Output file path. Writes to stdout if not provided."
    )
    parser.add_argument(
        "--since",
        help="Filter conversations created on or after this date (YYYY-MM-DD)."
    )

    args = parser.parse_args()

    try:
        # Explicitly handle encoding for robust unicode support
        if args.input_file == '-':
            json_data = json.load(sys.stdin)
        else:
            with open(args.input_file, 'r', encoding='utf-8') as f:
                json_data = json.load(f)
    except (json.JSONDecodeError, FileNotFoundError, UnicodeDecodeError) as e:
        print(f"Error reading input file: {e}", file=sys.stderr)
        sys.exit(1)

    markdown_output = extract_conversations_markdown(json_data, args.since)

    if args.output:
        try:
            with open(args.output, 'w', encoding='utf-8') as f:
                f.write(markdown_output)
            print(f"Recap successfully written to {args.output}", file=sys.stderr)
        except IOError as e:
            print(f"Error writing to output file: {e}", file=sys.stderr)
            sys.exit(1)
    else:
        # Ensure stdout is configured for UTF-8
        sys.stdout.reconfigure(encoding='utf-8')
        print(markdown_output)


if __name__ == "__main__":
    main()