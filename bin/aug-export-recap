#!/usr/bin/env python3
import sys
import os
from pathlib import Path
import re

# Add src directory to Python path
script_dir = Path(__file__).parent
src_dir = script_dir.parent / "src"
sys.path.insert(0, str(src_dir))

import argparse
from augment_ai.aug_common import load_json_input, save_json_output
from datetime import datetime, timezone

def sanitize_markdown(text):
    """Sanitize text to prevent markdown formatting issues."""
    if not text:
        return ""
    
    text = str(text)
    
    # DEBUG: Show what we're starting with
    if '\\n' in text or '\n' in text:
        print(f"üêõ DEBUG: Input contains newlines: {repr(text[:100])}", file=sys.stderr)
    
    # Handle unicode escape sequences with regex instead of unicode_escape
    def decode_unicode_escapes(match):
        try:
            return chr(int(match.group(1), 16))
        except ValueError:
            return match.group(0)
    
    # Replace \uXXXX sequences with actual unicode characters
    text = re.sub(r'\\u([0-9a-fA-F]{4})', decode_unicode_escapes, text)
    
    # Replace literal \n with actual newlines, then normalize to spaces
    original_text = text
    text = text.replace('\\n', '\n')
    
    # Also handle escaped newlines that might be double-escaped
    text = text.replace('\\\\n', '\n')
    
    # DEBUG: Show after newline replacement
    if original_text != text:
        print(f"üêõ DEBUG: After newline replacement: {repr(text[:100])}", file=sys.stderr)
    
    # Normalize all whitespace to single spaces
    before_normalize = text
    text = re.sub(r'\s+', ' ', text)
    
    # DEBUG: Show after normalization
    if before_normalize != text:
        print(f"üêõ DEBUG: After normalization: {repr(text[:100])}", file=sys.stderr)
    
    # Only escape problematic markdown chars that would break structure
    dangerous_chars = ['`', '#', '[', ']']
    for char in dangerous_chars:
        text = text.replace(char, f'\\{char}')
    
    # Remove control characters
    text = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', text)
    
    # DEBUG: Final check for remaining \n
    if '\\n' in text:
        print(f"üêõ DEBUG: Still has \\n after processing: {repr(text[:100])}", file=sys.stderr)
    
    return text.strip()

def extract_project_recap(json_data, options):
    """Extract project recap data for historical context."""
    recap = {
        "project_timeline": [],
        "key_decisions": [],
        "file_evolution": {},
        "error_patterns": [],
        "tool_usage": []
    }
    
    conversations = json_data.get("conversations", {})
    
    # Filter by date if specified
    since_date = None
    if hasattr(options, 'since') and options.since:
        # Handle different date formats
        since_str = options.since
        if 'T' not in since_str:
            # Add time and timezone if only date provided
            since_str = f"{since_str}T00:00:00+00:00"
        elif 'Z' in since_str:
            since_str = since_str.replace('Z', '+00:00')
        elif '+' not in since_str and 'Z' not in since_str:
            # Add timezone if missing
            since_str = f"{since_str}+00:00"
        
        since_date = datetime.fromisoformat(since_str)
    
    for conv_id, conv in conversations.items():
        # Skip if filtering by date
        if since_date:
            created_iso = conv.get("createdAtIso", "")
            if created_iso:
                created = datetime.fromisoformat(created_iso.replace('Z', '+00:00'))
                if created < since_date:
                    continue

def get_conversation_title(conv):
    """Extract a meaningful title from the conversation name or first message."""
    # First try to get the name field from the conversation
    name = conv.get("name", "")
    if name and name.strip():
        return sanitize_markdown(name.strip())
    
    # Fallback to first message if no name
    chat_history = conv.get("chatHistory", [])
    if not chat_history:
        return "Empty Conversation"
    
    first_message = chat_history[0]
    request = first_message.get("request_message", "")
    
    if not request:
        return "Untitled Conversation"
    
    # Clean and truncate the request to make a title
    title = sanitize_markdown(request)
    # Remove common prefixes
    title = re.sub(r'^(Act as|Please|Can you|How to|I need|Help me)\s+', '', title, flags=re.IGNORECASE)
    # Take first meaningful part (up to 60 chars)
    title = title[:60].strip()
    if len(request) > 60:
        title += "..."
    
    return title or "Untitled Conversation"

def extract_conversations_markdown(json_data, options):
    """Extract all conversations in markdown format with truncated content."""
    conversations = json_data.get("conversations", {})
    
    # Filter by date if specified
    since_date = None
    if hasattr(options, 'since') and options.since:
        since_str = options.since
        if 'T' not in since_str:
            since_str = f"{since_str}T00:00:00+00:00"
        elif 'Z' in since_str:
            since_str = since_str.replace('Z', '+00:00')
        elif '+' not in since_str and 'Z' not in since_str:
            since_str = f"{since_str}+00:00"
        since_date = datetime.fromisoformat(since_str)
    
    markdown_output = []
    markdown_output.append("# All Conversations Overview\n")
    
    # Sort conversations by creation date
    sorted_convs = sorted(
        conversations.items(),
        key=lambda x: x[1].get("createdAtIso", ""),
        reverse=True
    )
    
    for conv_id, conv in sorted_convs:
        # Skip if filtering by date
        if since_date:
            created_iso = conv.get("createdAtIso", "")
            if created_iso:
                created = datetime.fromisoformat(created_iso.replace('Z', '+00:00'))
                if created < since_date:
                    continue
        
        created_at = conv.get("createdAtIso", "Unknown")
        last_interaction = conv.get("lastInteractedAtIso", "Unknown")
        is_pinned = "üìå" if conv.get("isPinned", False) else ""
        
        # Get conversation title from first message
        title = get_conversation_title(conv)
        safe_conv_id = sanitize_markdown(conv_id[:8])
        
        markdown_output.append(f"## {is_pinned} {title}")
        markdown_output.append(f"**ID:** {safe_conv_id}...")
        markdown_output.append(f"**Created:** {created_at}")
        markdown_output.append(f"**Last Interaction:** {last_interaction}")
        markdown_output.append("")
        
        chat_history = conv.get("chatHistory", [])
        if not chat_history:
            markdown_output.append("*No messages*\n")
            continue
            
        for i, message in enumerate(chat_history, 1):
            request = message.get("request_message", "")
            response = message.get("response_text", "")
            status = message.get("status", "unknown")
            timestamp = message.get("timestamp", "")
            
            # Sanitize and truncate content
            request_clean = sanitize_markdown(request)
            response_clean = sanitize_markdown(response)
            
            request_short = (request_clean[:47] + "...") if len(request_clean) > 50 else request_clean
            response_short = (response_clean[:47] + "...") if len(response_clean) > 50 else response_clean
            
            status_icon = {
                "success": "‚úÖ",
                "error": "‚ùå", 
                "pending": "‚è≥",
                "draft": "üìù",
                "cancelled": "üö´"
            }.get(status, "‚ùì")
            
            markdown_output.append(f"### Message {i} {status_icon}")
            if timestamp:
                safe_timestamp = sanitize_markdown(timestamp)
                markdown_output.append(f"*{safe_timestamp}*")
            
            if request_short:
                markdown_output.append(f"**Request:** {request_short}")
            if response_short:
                markdown_output.append(f"**Response:** {response_short}")
            markdown_output.append("")
        
        markdown_output.append("---\n")
    
    return "\n".join(markdown_output)

def main():
    parser = argparse.ArgumentParser(description="Export chat recap data")
    parser.add_argument("input_file", nargs='?', default='-',
                       help="Input JSON file path (default: stdin)")
    parser.add_argument("--output", "-o", help="Output file path (default: stdout)")
    parser.add_argument("--since", help="Filter conversations since date (YYYY-MM-DD)")
    parser.add_argument("--format", choices=["recap", "conversations"], 
                       default="recap", help="Output format")
    
    args = parser.parse_args()
    
    json_data = load_json_input(args.input_file)
    
    if args.format == "conversations":
        output = extract_conversations_markdown(json_data, args)
        # For markdown output, write directly as text, not JSON
        if args.output:
            with open(args.output, 'w', encoding='utf-8') as f:
                f.write(output)
        else:
            print(output)
    else:
        output = extract_project_recap(json_data, args)
        save_json_output(output, args.output)

if __name__ == "__main__":
    main()