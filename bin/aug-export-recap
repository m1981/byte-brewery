#!/usr/bin/env python3
"""
A tool to generate a readable Markdown recap from an Agent AI state file.
"""
import sys
import re
import argparse
import json
from pathlib import Path
from datetime import datetime, timezone
from typing import Dict, Any, List, Optional, Tuple


# --- Text Processing Utilities ---

def filter_file_edits(text: str, verbose: bool = False) -> str:
    """Finds agent-generated file edit blocks and replaces them with a summary message."""
    if not text: return ""
    pattern = re.compile(r"```[^\n]*?path=([^\s]+)\s+mode=\w+.*?```", re.DOTALL)
    if verbose:
        print("\n--- REGEX DEBUG START ---", file=sys.stderr)
        print(f"Analyzing response text snippet:\n---\n{text[:350]}...\n---", file=sys.stderr)
        matches = list(pattern.finditer(text))
        if not matches:
            print("‚úÖ Regex found NO file edit blocks to replace.", file=sys.stderr)
        else:
            print(f"‚úÖ Regex found {len(matches)} file edit block(s):", file=sys.stderr)
            for i, match in enumerate(matches):
                path = match.group(1)
                print(f"  - Match {i + 1}: Found and replaced block for path='{path}'.", file=sys.stderr)
        print("--- REGEX DEBUG END ---\n", file=sys.stderr)

    def replacer(match: re.Match) -> str:
        path = match.group(1)
        return f"\n> *[File edit performed on `{path}`]*\n"

    return pattern.sub(replacer, text)


def clean_text_content(text: Optional[str]) -> str:
    """Non-destructively clean text content for Markdown display."""
    if not text: return ""
    text = str(text)

    def decode_unicode_escapes(match):
        try:
            return chr(int(match.group(1), 16))
        except (ValueError, TypeError):
            return match.group(0)

    text = re.sub(r'\\u([0-9a-fA-F]{4})', decode_unicode_escapes, text)
    text = text.replace('\\n', '\n')
    text = re.sub(r'[\x00-\x08\x0b\x0c\x0e-\x1f\x7f]', '', text)
    return text


def smart_truncate(text: str, max_length: int) -> str:
    """Truncate text for a summary, prioritizing the first meaningful line."""
    if not text: return ""
    lines = [line.strip() for line in text.splitlines() if line.strip() and not line.strip().startswith('>*[File edit')]
    first_meaningful_line = lines[0] if lines else ""
    if not first_meaningful_line: return text[:max_length].strip() + "..."
    if len(first_meaningful_line) > max_length: return first_meaningful_line[:max_length].strip() + "..."
    return first_meaningful_line


def is_primarily_code(text: str, threshold: float = 0.5) -> bool:
    """
    Determines if a string is composed mainly of code blocks.
    """
    code_block_pattern = re.compile(r"```.*?```", re.DOTALL)
    total_len = len(text)
    if total_len == 0:
        return False

    code_len = sum(len(match.group(0)) for match in code_block_pattern.finditer(text))

    return (code_len / total_len) > threshold


# --- Markdown Generation ---

def get_conversation_title(conv: Dict[str, Any]) -> str:
    name = conv.get("name", "").strip()
    if name: return name
    chat_history = conv.get("chatHistory", [])
    if not chat_history: return "Empty Conversation"
    first_message_request = chat_history[0].get("request_message", "")
    if not first_message_request: return "Untitled Conversation"
    first_line = first_message_request.split('\n')[0].strip()
    title = re.sub(r'^(act as|please|can you|explain|help me with|i need)\s+', '', first_line,
                   flags=re.IGNORECASE).strip()
    return smart_truncate(title, 80) or "Untitled Conversation"


def create_markdown_anchor(text: str) -> str:
    anchor = re.sub(r'[^\w\s-]', '', text.lower())
    anchor = re.sub(r'[-\s]+', '-', anchor).strip('-')
    return anchor


def _parse_iso_date(date_str: str) -> Optional[datetime]:
    if not date_str: return None
    try:
        return datetime.fromisoformat(date_str.replace('Z', '+00:00'))
    except (ValueError, TypeError):
        return None


def extract_conversations_markdown(json_data: Dict[str, Any], since: Optional[str], show_edits: bool, verbose: bool,
                                   debug_truncation: bool) -> str:
    """Generate a full Markdown recap from the conversation data."""
    conversations = json_data.get("conversations", {})
    since_date = _parse_iso_date(f"{since}T00:00:00+00:00") if since else None

    sorted_convs: List[Tuple[str, Dict[str, Any]]] = sorted(
        conversations.items(), key=lambda item: item[1].get("createdAtIso", ""), reverse=True
    )

    filtered_convs = [
        (conv_id, conv) for conv_id, conv in sorted_convs
        if not since_date or (_parse_iso_date(conv.get("createdAtIso", "")) or datetime.min.replace(
            tzinfo=timezone.utc)) >= since_date
    ]

    md = ["# Project Recap"]
    md.append("\n## Table of Contents\n")
    if not filtered_convs:
        md.append("*No conversations found for the selected period.*")
    else:
        for _, conv in filtered_convs:
            title = get_conversation_title(conv)
            anchor = create_markdown_anchor(title)
            created_at = (conv.get("createdAtIso") or "Unknown")[:10]
            pin_icon = "üìå " if conv.get("isPinned") else ""
            md.append(f"- [{pin_icon}{title}](#{anchor}) *({created_at})*")

    for conv_id, conv in filtered_convs:
        md.append("\n---\n")
        title = get_conversation_title(conv)
        pin_icon = "üìå " if conv.get("isPinned") else ""
        md.append(f"## {pin_icon}{title}")

        created_at, last_interaction = conv.get("createdAtIso", "N/A"), conv.get("lastInteractedAtIso", "N/A")
        md.extend([f"| ID | Created | Last Interaction |", f"|:---|:---|:---|",
                   f"| `{conv_id[:8]}` | {created_at} | {last_interaction} |"])

        chat_history = conv.get("chatHistory", [])
        if not chat_history:
            md.append("\n*This conversation has no messages.*")
            continue

        mentioned_files = {f"`{item['name']}`" for msg in chat_history for item in msg.get("mentioned_items", []) if
                           item.get("name")}
        if mentioned_files: md.append(f"\n**Mentioned Files:** {', '.join(sorted(list(mentioned_files)))}")

        for i, msg in enumerate(chat_history, 1):
            request_raw = clean_text_content(msg.get("request_message"))
            response_clean = clean_text_content(msg.get("response_text"))

            # --- TRUNCATION LOGIC WITH DEBUGGING ---
            request_len = len(request_raw)
            is_code_heavy = is_primarily_code(request_raw)

            if debug_truncation:
                print("\n--- TRUNCATION DEBUG START ---", file=sys.stderr)
                print(f"Conversation '{title}', Turn {i}", file=sys.stderr)
                print(f"  - Request Length: {request_len} chars", file=sys.stderr)
                print(f"  - Is primarily code (>50%): {is_code_heavy}", file=sys.stderr)

            if is_code_heavy and request_len > 200:
                if debug_truncation: print("  - Decision: TRUNCATE code block request.", file=sys.stderr)
                request_to_display = request_raw[:200] + "\n... [request truncated] ..."
                request_summary = "User provided a large code/log excerpt..."
            else:
                if debug_truncation: print("  - Decision: DO NOT truncate request.", file=sys.stderr)
                request_to_display = request_raw
                request_summary = smart_truncate(request_raw, 200)

            if debug_truncation: print("--- TRUNCATION DEBUG END ---\n", file=sys.stderr)

            response_to_display = response_clean if show_edits else filter_file_edits(response_clean, verbose=verbose)
            response_summary = smart_truncate(response_to_display, 300)

            status, timestamp = msg.get("status", "unknown"), msg.get("timestamp", "")
            status_icon = {"success": "‚úÖ", "error": "‚ùå", "pending": "‚è≥", "draft": "üìù", "cancelled": "üö´"}.get(status,
                                                                                                             "‚ùì")

            md.append(f"\n### Turn {i} ({status.capitalize()}) {status_icon}")
            if timestamp: md.append(f"*{timestamp}*\n")

            if request_to_display:
                md.append(
                    f'<details>\n  <summary><strong>Request:</strong> {request_summary}</summary>\n\n```\n{request_to_display}\n```\n</details>\n')

            if response_to_display.strip():
                md.append(
                    f'<details>\n  <summary><strong>Response:</strong> {response_summary}</summary>\n\n{response_to_display}\n</details>\n')

    return "\n".join(md)


# --- Main Execution ---

def main():
    """Main function to parse arguments and generate the recap."""
    parser = argparse.ArgumentParser(description="Generate a Markdown recap from an Agent AI state file.",
                                     formatter_class=argparse.RawTextHelpFormatter)
    parser.add_argument("input_file", nargs='?', default='-',
                        help="Input JSON file path. Reads from stdin if not provided.")
    parser.add_argument("-o", "--output", help="Output file path. Writes to stdout if not provided.")
    parser.add_argument("--since", help="Filter conversations created on or after this date (YYYY-MM-DD).")
    parser.add_argument("--show-edits", action="store_true",
                        help="Include full content of agent file edits in the output.")
    parser.add_argument("-v", "--verbose", action="store_true",
                        help="Print verbose debug information for regex filtering to stderr.")
    parser.add_argument("--debug-truncation", action="store_true",
                        help="Print debug information for user request truncation logic.")

    args = parser.parse_args()

    try:
        if args.input_file == '-':
            sys.stdin.reconfigure(encoding='utf-8')
            json_data = json.load(sys.stdin)
        else:
            with open(args.input_file, 'r', encoding='utf-8') as f:
                json_data = json.load(f)
    except (json.JSONDecodeError, FileNotFoundError, UnicodeDecodeError) as e:
        print(f"Error reading input file: {e}", file=sys.stderr)
        sys.exit(1)

    markdown_output = extract_conversations_markdown(json_data, args.since, args.show_edits, args.verbose,
                                                     args.debug_truncation)

    if args.output:
        try:
            with open(args.output, 'w', encoding='utf-8') as f:
                f.write(markdown_output)
            print(f"Recap successfully written to {args.output}", file=sys.stderr)
        except IOError as e:
            print(f"Error writing to output file: {e}", file=sys.stderr)
            sys.exit(1)
    else:
        sys.stdout.reconfigure(encoding='utf-8')
        print(markdown_output)


if __name__ == "__main__":
    main()